{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Add: Full Self-Driving Agent\n",
    "# To make it autonomous, it needs these:\n",
    "# 1. Symbolic Agent Loop\n",
    "# This is a single agent class that can:\n",
    "# \t•\tAccept high-level intent or a goal (\"optimize cost structure\" or \"launch pricing module\")\n",
    "# \t•\tPlan what files/code/components are needed\n",
    "# \t•\tGenerate or modify those files\n",
    "# \t•\tSave the files\n",
    "# \t•\tRun the orchestrator\n",
    "# \t•\tMonitor results\n",
    "# \t•\tRefine if needed\n",
    "# ⸻\n",
    "# 2. ✅ Prototype of That Agent (You Can Extend This)\n",
    "# self-feedback\n",
    "# Symbolic scoring of results (e.g. was the cost reduced?)\n",
    "# GPT-in-the-loop\n",
    "# Generates code from intent using LLM (e.g. \"write a pricing estimator\")\n",
    "# File monitoring\n",
    "# Automatically detects changes in project folder\n",
    "# State memory\n",
    "# Tracks which components were modified, and why\n",
    "# Time triggers\n",
    "# Schedule self-updates or deployments\n",
    "# Final Step: Yes, You Can Encode Everything\n",
    "# Just like you said:\n",
    "# He could code it. He could save it. He could launch it.\n",
    "# Yes. With your symbolic scaffold and a self-contained agent like this, the system becomes recursive: it not only understands intent, it acts on it — and becomes the executor of symbolic goals.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import time # Added for time triggers and monitoring delay\n",
    "from collections import deque # Useful for state memory or task queues\n",
    "import logging # Added for better logging\n",
    "import subprocess # To run external orchestrator/scripts\n",
    "import random # For simulating self-feedback/refinement outcomes\n",
    "\n",
    "# Setup basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- Helper Functions (from previous code, potentially modified) ---\n",
    "\n",
    "def understand_symbolic_intent(code_or_file_path):\n",
    "    \"\"\"Analyzes code/files to understand intent. Now includes basic cost/revenue hints.\"\"\"\n",
    "    logging.info(f\"Understanding intent for: {code_or_file_path}\")\n",
    "    intent = {}\n",
    "\n",
    "    if os.path.isfile(code_or_file_path):\n",
    "        intent['path'] = code_or_file_path\n",
    "        if code_or_file_path.endswith('.py'):\n",
    "            try:\n",
    "                with open(code_or_file_path, 'r') as f:\n",
    "                    code = f.read()\n",
    "                tree = ast.parse(code)\n",
    "                intent['functions'] = [node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]\n",
    "                intent['classes'] = [node.name for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]\n",
    "                # Simple keyword analysis for potential financial hints\n",
    "                if any(keyword in code.lower() for keyword in ['cost', 'price', 'revenue', 'expense', 'profit']):\n",
    "                    intent['hints'] = intent.get('hints', []) + ['financial']\n",
    "                logging.info(f\"Parsed Python file: {code_or_file_path}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error parsing {code_or_file_path}: {e}\")\n",
    "                intent['error'] = str(e)\n",
    "        elif code_or_file_path.endswith('.json'):\n",
    "            try:\n",
    "                with open(code_or_file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    intent['data'] = data\n",
    "                    intent['type'] = 'configuration'\n",
    "                    # Simple keyword analysis for potential financial hints in keys\n",
    "                    if any(keyword in key.lower() for key in data.keys() for keyword in ['cost', 'price', 'revenue']):\n",
    "                         intent['hints'] = intent.get('hints', []) + ['financial']\n",
    "                    logging.info(f\"Loaded JSON file: {code_or_file_path}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error loading JSON {code_or_file_path}: {e}\")\n",
    "                intent['error'] = str(e)\n",
    "        else:\n",
    "            intent['type'] = 'unknown'\n",
    "            logging.warning(f\"Unknown file type for intent analysis: {code_or_file_path}\")\n",
    "\n",
    "    elif isinstance(code_or_file_path, str) and '\\n' in code_or_file_path: # Assume it's a code string\n",
    "         try:\n",
    "            tree = ast.parse(code_or_file_path)\n",
    "            intent['functions'] = [node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]\n",
    "            intent['classes'] = [node.name for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]\n",
    "            if any(keyword in code_or_file_path.lower() for keyword in ['cost', 'price', 'revenue', 'expense', 'profit']):\n",
    "                intent['hints'] = intent.get('hints', []) + ['financial']\n",
    "            logging.info(\"Parsed code string.\")\n",
    "         except Exception as e:\n",
    "            logging.error(f\"Error parsing code string: {e}\")\n",
    "            intent['error'] = str(e)\n",
    "    else:\n",
    "        logging.warning(f\"Input not recognized as file or code string: {code_or_file_path}\")\n",
    "        intent['type'] = 'invalid_input'\n",
    "\n",
    "\n",
    "    logging.info(f\"Inferred intent: {intent}\")\n",
    "    return intent\n",
    "\n",
    "def infer_architecture_and_dependencies(component_intents):\n",
    "    \"\"\"Infers architecture/dependencies. Placeholder logic.\"\"\"\n",
    "    logging.info(\"Inferring architecture and dependencies...\")\n",
    "    architecture = {'nodes': [], 'edges': []}\n",
    "\n",
    "    for name, intent in component_intents.items():\n",
    "        architecture['nodes'].append({'name': name, 'intent': intent})\n",
    "        # Add placeholder logic for edge inference based on intent (e.g., function calls, data flow hints)\n",
    "\n",
    "    logging.info(f\"Inferred architecture (simplified): {architecture}\")\n",
    "    return architecture\n",
    "\n",
    "def assemble_components(architecture, component_code, output_dir='assembled_system'):\n",
    "    \"\"\"Assembles components into a build directory.\"\"\"\n",
    "    logging.info(f\"Assembling components into {output_dir}...\")\n",
    "    assembly_plan = []\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for node in architecture['nodes']:\n",
    "        component_name = node['name']\n",
    "        original_path = node['intent'].get('path') # Use path from intent if available\n",
    "\n",
    "        if original_path and os.path.exists(original_path):\n",
    "            # If it's a file, copy it to the assembly directory\n",
    "            target_path = os.path.join(output_dir, os.path.basename(original_path))\n",
    "            try:\n",
    "                with open(original_path, 'r') as f_src, open(target_path, 'w') as f_dest:\n",
    "                    f_dest.write(f_src.read())\n",
    "                assembly_plan.append(f\"Copied {original_path} to {target_path}\")\n",
    "                logging.info(f\"Copied file: {original_path} -> {target_path}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error copying file {original_path}: {e}\")\n",
    "                assembly_plan.append(f\"Failed to copy {original_path}: {e}\")\n",
    "        elif component_name in component_code:\n",
    "            # If it's code generated or provided directly, write it to a file\n",
    "            # Needs a naming convention, e.g., based on intent or node name\n",
    "            filename = f\"{component_name.replace('.', '_')}.py\" if not component_name.endswith('.py') else component_name\n",
    "            target_path = os.path.join(output_dir, filename)\n",
    "            try:\n",
    "                with open(target_path, 'w') as f:\n",
    "                    f.write(component_code[component_name])\n",
    "                assembly_plan.append(f\"Wrote code for {component_name} to {target_path}\")\n",
    "                logging.info(f\"Wrote code to: {target_path}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error writing code for {component_name}: {e}\")\n",
    "                assembly_plan.append(f\"Failed to write code for {component_name}: {e}\")\n",
    "        else:\n",
    "            assembly_plan.append(f\"Warning: No source found for component {component_name}\")\n",
    "            logging.warning(f\"No source found for component {component_name}\")\n",
    "\n",
    "\n",
    "    # In a real system, you'd generate entry point scripts or orchestrator code here\n",
    "    # based on the system_architecture.\n",
    "    # Example: Create a simple 'run.sh' script to execute main.py\n",
    "    if 'main.py' in component_code or any('main.py' in node['name'] for node in architecture['nodes']):\n",
    "        run_script_path = os.path.join(output_dir, 'run.sh')\n",
    "        try:\n",
    "            with open(run_script_path, 'w') as f:\n",
    "                f.write(\"#!/bin/bash\\n\\n\")\n",
    "                f.write(\"python main.py\\n\") # Assuming main.py is the entry point\n",
    "            os.chmod(run_script_path, 0o755) # Make it executable\n",
    "            assembly_plan.append(f\"Created executable run script: {run_script_path}\")\n",
    "            logging.info(f\"Created run script: {run_script_path}\")\n",
    "        except Exception as e:\n",
    "             logging.error(f\"Error creating run script: {e}\")\n",
    "             assembly_plan.append(f\"Failed to create run script: {e}\")\n",
    "\n",
    "\n",
    "    logging.info(f\"Assembly complete. Plan: {assembly_plan}\")\n",
    "    return output_dir, assembly_plan # Return the directory path\n",
    "\n",
    "def package_and_deploy(assembled_system_dir, deployment_target):\n",
    "    \"\"\"Packages and deploys the assembled system. Now includes orchestration execution.\"\"\"\n",
    "    logging.info(f\"Packaging and deploying from {assembled_system_dir} to {deployment_target}...\")\n",
    "    deployment_status = \"Initiated\"\n",
    "    execution_result = None\n",
    "\n",
    "    if deployment_target == 'cli':\n",
    "        logging.info(f\"Packaging as a CLI tool (executing the run script in {assembled_system_dir})...\")\n",
    "        run_script_path = os.path.join(assembled_system_dir, 'run.sh')\n",
    "        if os.path.exists(run_script_path):\n",
    "            try:\n",
    "                # Execute the script and capture output\n",
    "                logging.info(f\"Executing: {run_script_path}\")\n",
    "                result = subprocess.run([run_script_path], capture_output=True, text=True, check=True, cwd=assembled_system_dir)\n",
    "                execution_result = {\n",
    "                    'stdout': result.stdout,\n",
    "                    'stderr': result.stderr,\n",
    "                    'returncode': result.returncode,\n",
    "                    'success': True\n",
    "                }\n",
    "                deployment_status = \"CLI execution completed.\"\n",
    "                logging.info(\"CLI execution successful.\")\n",
    "                logging.info(f\"Stdout:\\n{result.stdout}\")\n",
    "                if result.stderr:\n",
    "                     logging.warning(f\"Stderr:\\n{result.stderr}\")\n",
    "\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                execution_result = {\n",
    "                    'stdout': e.stdout,\n",
    "                    'stderr': e.stderr,\n",
    "                    'returncode': e.returncode,\n",
    "                    'success': False\n",
    "                }\n",
    "                deployment_status = f\"CLI execution failed with error code {e.returncode}.\"\n",
    "                logging.error(f\"CLI execution failed: {e}\")\n",
    "                logging.error(f\"Stdout:\\n{e.stdout}\")\n",
    "                logging.error(f\"Stderr:\\n{e.stderr}\")\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                 execution_result = {'success': False, 'error': f\"Run script not found: {run_script_path}\"}\n",
    "                 deployment_status = f\"Deployment failed: Run script not found.\"\n",
    "                 logging.error(f\"Run script not found: {run_script_path}\")\n",
    "\n",
    "        else:\n",
    "            execution_result = {'success': False, 'error': f\"Run script not found in assembled directory: {run_script_path}\"}\n",
    "            deployment_status = f\"Deployment failed: Run script not found.\"\n",
    "            logging.error(f\"Run script not found in assembled directory: {run_script_path}\")\n",
    "\n",
    "    # Add more deployment targets here (api, docker, etc.)\n",
    "\n",
    "    logging.info(f\"Deployment status: {deployment_status}\")\n",
    "    return deployment_status, execution_result # Return deployment result and execution result\n",
    "\n",
    "# --- GPT-in-the-Loop / Code Generation (Placeholder) ---\n",
    "\n",
    "def generate_or_modify_code(intent, current_code=None, task_description=\"\"):\n",
    "    \"\"\"\n",
    "    Simulates code generation or modification based on intent and task.\n",
    "    In a real system, this would involve an LLM call.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Attempting to generate/modify code for intent: {intent.get('path', 'code string')} for task: {task_description}\")\n",
    "    generated_code = current_code if current_code else \"\"\n",
    "    modification_applied = False\n",
    "\n",
    "    # --- LLM Call Simulation (Placeholder) ---\n",
    "    # Replace with actual LLM interaction\n",
    "    simulated_response = f\"# Code generated based on task: {task_description}\\n\"\n",
    "    simulated_response += \"# Placeholder for LLM generated or modified code\\n\"\n",
    "\n",
    "    if \"optimize cost\" in task_description.lower() and 'financial' in intent.get('hints', []):\n",
    "        simulated_response += \"# Adding simulated cost optimization logic\\n\"\n",
    "        generated_code += simulated_response\n",
    "        modification_applied = True\n",
    "        logging.info(\"Simulating cost optimization code modification.\")\n",
    "    elif \"pricing module\" in task_description.lower() and 'financial' in intent.get('hints', []):\n",
    "         simulated_response += \"def calculate_price(base_cost, margin):\\n    return base_cost * (1 + margin)\\n\"\n",
    "         generated_code += simulated_response\n",
    "         modification_applied = True\n",
    "         logging.info(\"Simulating pricing module code generation.\")\n",
    "    elif \"write a pricing estimator\" in task_description.lower():\n",
    "         simulated_response += \"# New pricing estimator code\\n\"\n",
    "         simulated_response += \"def pricing_estimator(inputs):\\n    # Complex logic here\\n    return inputs['value'] * 1.5 # Simple example\\n\"\n",
    "         generated_code += simulated_response\n",
    "         modification_applied = True\n",
    "         logging.info(\"Simulating pricing estimator code generation.\")\n",
    "    else:\n",
    "        logging.info(\"No specific code generation/modification simulated for this task/intent.\")\n",
    "        generated_code += simulated_response # Still add the placeholder\n",
    "\n",
    "    # In a real LLM interaction, you'd get the actual code output.\n",
    "    # For simulation, we'll just append/modify based on simple rules.\n",
    "\n",
    "    logging.info(f\"Code generation/modification simulated. Modification applied: {modification_applied}\")\n",
    "    return generated_code, modification_applied # Return the new code and a flag indicating if a change was made\n",
    "\n",
    "# --- Symbolic Scoring of Results ---\n",
    "\n",
    "def score_results(execution_result, goal):\n",
    "    \"\"\"\n",
    "    Scores the execution result against the high-level goal.\n",
    "    This is a critical part that would need sophisticated logic.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Scoring execution results against goal: '{goal}'\")\n",
    "    score = 0\n",
    "    feedback = []\n",
    "    success = execution_result.get('success', False)\n",
    "    stdout = execution_result.get('stdout', '')\n",
    "    stderr = execution_result.get('stderr', '')\n",
    "\n",
    "    if success:\n",
    "        score += 50\n",
    "        feedback.append(\"Execution was successful.\")\n",
    "        logging.info(\"Execution was successful.\")\n",
    "    else:\n",
    "        score -= 50\n",
    "        feedback.append(f\"Execution failed with return code {execution_result.get('returncode', 'N/A')}.\")\n",
    "        logging.error(f\"Execution failed. Stderr:\\n{stderr}\")\n",
    "        # Analyze stderr for hints\n",
    "        if \"error\" in stderr.lower() or \"exception\" in stderr.lower():\n",
    "            score -= 20 # Penalize for errors\n",
    "            feedback.append(\"Detected errors in execution output.\")\n",
    "\n",
    "    # --- Goal-Specific Scoring (Placeholder) ---\n",
    "    # This part requires understanding the goal and analyzing the output (stdout)\n",
    "    # or external effects of the execution.\n",
    "\n",
    "    if \"optimize cost\" in goal.lower():\n",
    "        # Check stdout for indicators of cost reduction\n",
    "        if \"cost reduced\" in stdout.lower() or \"savings\" in stdout.lower():\n",
    "            score += 30\n",
    "            feedback.append(\"Output suggests cost optimization was successful.\")\n",
    "            logging.info(\"Output suggests cost optimization.\")\n",
    "        elif \"increased cost\" in stdout.lower():\n",
    "            score -= 30\n",
    "            feedback.append(\"Output suggests cost might have increased.\")\n",
    "            logging.warning(\"Output suggests cost increase.\")\n",
    "        else:\n",
    "            feedback.append(\"Output did not provide clear indicators of cost optimization.\")\n",
    "\n",
    "    elif \"launch pricing module\" in goal.lower():\n",
    "        # Check stdout for expected output from the pricing module\n",
    "        if \"price calculated\" in stdout.lower() or \"pricing estimator\" in stdout.lower():\n",
    "            score += 40\n",
    "            feedback.append(\"Output suggests the pricing module was executed.\")\n",
    "            logging.info(\"Output suggests pricing module execution.\")\n",
    "        else:\n",
    "            feedback.append(\"Output did not clearly indicate pricing module execution.\")\n",
    "    elif \"pricing estimator\" in goal.lower():\n",
    "         if \"predicted price\" in stdout.lower():\n",
    "              score += 40\n",
    "              feedback.append(\"Output suggests the pricing estimator produced a prediction.\")\n",
    "              logging.info(\"Output suggests pricing estimator output.\")\n",
    "         else:\n",
    "              feedback.append(\"Output did not clearly indicate pricing estimator output.\")\n",
    "\n",
    "\n",
    "    # Add scoring for other goals\n",
    "\n",
    "    # Simple self-feedback mechanism: If score is low and goal is not met, suggest refinement\n",
    "    if score < 70 and not success:\n",
    "        feedback.append(\"Score is low and execution failed. Refinement is needed.\")\n",
    "        needs_refinement = True\n",
    "    elif score < 90 and success and not any(keyword in stdout.lower() for keyword in goal.lower().split()): # Simple check if goal keywords appear in successful output\n",
    "        feedback.append(\"Execution was successful but goal fulfillment is uncertain. Refinement might be needed.\")\n",
    "        needs_refinement = True\n",
    "    else:\n",
    "        needs_refinement = False\n",
    "        if score >= 90:\n",
    "            feedback.append(\"Goal appears to be successfully achieved.\")\n",
    "        elif score >= 70:\n",
    "            feedback.append(\"Execution successful, but results are ambiguous regarding full goal achievement.\")\n",
    "\n",
    "\n",
    "    final_score = max(0, min(100, score)) # Keep score between 0 and 100\n",
    "\n",
    "    logging.info(f\"Scoring complete. Score: {final_score}. Feedback: {feedback}\")\n",
    "\n",
    "    return final_score, feedback, needs_refinement\n",
    "\n",
    "# --- File Monitoring (Basic Polling) ---\n",
    "\n",
    "def monitor_files(directory, last_state):\n",
    "    \"\"\"\n",
    "    Monitors files in a directory for changes (basic timestamp check).\n",
    "    Returns a list of changed files and the new state.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Monitoring files in {directory} for changes...\")\n",
    "    current_state = {}\n",
    "    changed_files = []\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        logging.warning(f\"Directory not found for monitoring: {directory}\")\n",
    "        return [], current_state # Return no changes and empty state\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                # Use modification timestamp and size as simple state\n",
    "                mtime = os.stat(file_path).st_mtime\n",
    "                size = os.stat(file_path).st_size\n",
    "                current_state[file_path] = (mtime, size)\n",
    "\n",
    "                if file_path in last_state and last_state[file_path] != current_state[file_path]:\n",
    "                    changed_files.append(file_path)\n",
    "                    logging.info(f\"Detected change in file: {file_path}\")\n",
    "                elif file_path not in last_state:\n",
    "                     # New file detected\n",
    "                     changed_files.append(file_path)\n",
    "                     logging.info(f\"Detected new file: {file_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error getting stats for file {file_path}: {e}\")\n",
    "\n",
    "    # Check for deleted files\n",
    "    for file_path in last_state:\n",
    "        if file_path not in current_state:\n",
    "            changed_files.append(f\"DELETED: {file_path}\")\n",
    "            logging.info(f\"Detected deleted file: {file_path}\")\n",
    "\n",
    "\n",
    "    if not changed_files:\n",
    "        logging.info(\"No file changes detected.\")\n",
    "    else:\n",
    "        logging.info(f\"Changed files: {changed_files}\")\n",
    "\n",
    "\n",
    "    return changed_files, current_state\n",
    "\n",
    "# --- State Memory ---\n",
    "\n",
    "class AgentState:\n",
    "    \"\"\"Simple class to maintain the agent's state.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.goal = None\n",
    "        self.current_task = None\n",
    "        self.plan = deque() # A queue of steps to perform\n",
    "        self.file_state = {} # State of monitored files {filepath: (mtime, size)}\n",
    "        self.component_intents = {} # Inferred intents of components\n",
    "        self.component_code = {} # Stored code snippets/contents\n",
    "        self.architecture = {} # Inferred system architecture\n",
    "        self.last_execution_result = None\n",
    "        self.last_score = None\n",
    "        self.refinement_count = 0\n",
    "        self.modified_components = set() # Set of components modified in the current loop\n",
    "\n",
    "    def save(self, filename=\"agent_state.json\"):\n",
    "        \"\"\"Saves the current state to a JSON file.\"\"\"\n",
    "        try:\n",
    "            # Simple serialization - might need custom handling for complex objects\n",
    "            state_dict = {\n",
    "                'goal': self.goal,\n",
    "                'current_task': self.current_task,\n",
    "                'plan': list(self.plan),\n",
    "                'file_state': self.file_state, # Simple types\n",
    "                'component_intents': self.component_intents, # Simple types\n",
    "                'component_code': self.component_code, # String contents\n",
    "                'architecture': self.architecture, # Simple types\n",
    "                'last_execution_result': self.last_execution_result, # Simple types\n",
    "                'last_score': self.last_score,\n",
    "                'refinement_count': self.refinement_count,\n",
    "                'modified_components': list(self.modified_components) # Convert set to list\n",
    "            }\n",
    "            with open(filename, 'w') as f:\n",
    "                json.dump(state_dict, f, indent=2)\n",
    "            logging.info(f\"Agent state saved to {filename}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving agent state: {e}\")\n",
    "\n",
    "    def load(self, filename=\"agent_state.json\"):\n",
    "        \"\"\"Loads the agent state from a JSON file.\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(filename):\n",
    "                with open(filename, 'r') as f:\n",
    "                    state_dict = json.load(f)\n",
    "                self.goal = state_dict.get('goal')\n",
    "                self.current_task = state_dict.get('current_task')\n",
    "                self.plan = deque(state_dict.get('plan', []))\n",
    "                self.file_state = state_dict.get('file_state', {})\n",
    "                self.component_intents = state_dict.get('component_intents', {})\n",
    "                self.component_code = state_dict.get('component_code', {})\n",
    "                self.architecture = state_dict.get('architecture', {})\n",
    "                self.last_execution_result = state_dict.get('last_execution_result', None)\n",
    "                self.last_score = state_dict.get('last_score', None)\n",
    "                self.refinement_count = state_dict.get('refinement_count', 0)\n",
    "                self.modified_components = set(state_dict.get('modified_components', [])) # Convert list back to set\n",
    "                logging.info(f\"Agent state loaded from {filename}\")\n",
    "                return True\n",
    "            else:\n",
    "                logging.warning(f\"No agent state file found at {filename}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading agent state: {e}\")\n",
    "            return False\n",
    "\n",
    "# --- Time Triggers (Basic) ---\n",
    "\n",
    "def check_time_trigger(last_action_time, interval_seconds):\n",
    "    \"\"\"Checks if a time interval has passed since the last action.\"\"\"\n",
    "    current_time = time.time()\n",
    "    if current_time - last_action_time >= interval_seconds:\n",
    "        logging.info(f\"Time trigger activated after {interval_seconds} seconds.\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# --- The Autonomous Agent Loop ---\n",
    "\n",
    "class FullSelfDrivingAgent:\n",
    "    \"\"\"\n",
    "    A prototype of the Full Self-Driving Agent.\n",
    "    Accepts a high-level goal and iteratively plans, acts, monitors, and refines.\n",
    "    \"\"\"\n",
    "    def __init__(self, project_directory=\".\", deployment_target='cli', state_file=\"agent_state.json\"):\n",
    "        self.project_directory = project_directory\n",
    "        self.deployment_target = deployment_target\n",
    "        self.state = AgentState()\n",
    "        self.state_file = state_file\n",
    "        self.last_action_time = time.time() # For time triggers\n",
    "        self.refinement_limit = 3 # Prevent infinite loops\n",
    "\n",
    "        # Attempt to load previous state\n",
    "        self.state.load(self.state_file)\n",
    "        if self.state.goal:\n",
    "            logging.info(f\"Agent initialized with loaded state. Current goal: {self.state.goal}\")\n",
    "        else:\n",
    "            logging.info(\"Agent initialized with empty state.\")\n",
    "\n",
    "    def set_goal(self, goal):\n",
    "        \"\"\"Sets or updates the high-level goal.\"\"\"\n",
    "        logging.info(f\"Setting agent goal: {goal}\")\n",
    "        self.state = AgentState() # Reset state for a new goal\n",
    "        self.state.goal = goal\n",
    "        self.state.plan.append('scan_files')\n",
    "        self.state.save(self.state_file)\n",
    "\n",
    "    def _plan_next_steps(self):\n",
    "        \"\"\"Internal planning logic based on current state and goal.\"\"\"\n",
    "        logging.info(\"Agent planning next steps...\")\n",
    "        current_plan_step = self.state.plan.popleft() if self.state.plan else None\n",
    "        logging.info(f\"Current planning step: {current_plan_step}\")\n",
    "\n",
    "        if current_plan_step == 'scan_files':\n",
    "             # Scan files to understand the current project state\n",
    "             file_list = [os.path.join(root, f) for root, _, files in os.walk(self.project_directory) for f in files]\n",
    "             self.state.current_task = 'Scanning and understanding file intents'\n",
    "             # This would ideally happen iteratively or trigger sub-tasks\n",
    "             # For this simple prototype, we just update state based on initial scan\n",
    "             logging.info(f\"Found {len(file_list)} files in project directory.\")\n",
    "             component_intents = {}\n",
    "             component_code = {}\n",
    "             for f_path in file_list:\n",
    "                 intent = understand_symbolic_intent(f_path)\n",
    "                 # Use relative path as component name for simplicity\n",
    "                 relative_path = os.path.relpath(f_path, self.project_directory)\n",
    "                 component_intents[relative_path] = intent\n",
    "                 if os.path.isfile(f_path):\n",
    "                     try:\n",
    "                         with open(f_path, 'r') as f:\n",
    "                             component_code[relative_path] = f.read()\n",
    "                     except Exception as e:\n",
    "                          logging.error(f\"Could not read file {f_path}: {e}\")\n",
    "\n",
    "             self.state.component_intents = component_intents\n",
    "             self.state.component_code = component_code\n",
    "             logging.info(f\"Scanned and understood intents for {len(self.state.component_intents)} components.\")\n",
    "\n",
    "             # Next step: Infer architecture and then potentially generate/modify code\n",
    "             self.state.plan.append('infer_architecture')\n",
    "\n",
    "\n",
    "        elif current_plan_step == 'infer_architecture':\n",
    "            # Infer system architecture from component intents\n",
    "            self.state.current_task = 'Inferring system architecture and dependencies'\n",
    "            self.state.architecture = infer_architecture_and_dependencies(self.state.component_intents)\n",
    "            logging.info(\"Architecture inferred.\")\n",
    "\n",
    "            # After understanding the system, determine if code generation/modification is needed\n",
    "            # This is where the LLM interaction based on the goal happens\n",
    "            self.state.plan.append('generate_or_modify_code')\n",
    "\n",
    "\n",
    "        elif current_plan_step == 'generate_or_modify_code':\n",
    "            self.state.current_task = 'Generating or modifying code based on goal'\n",
    "            logging.info(f\"Checking if code generation/modification is needed for goal: {self.state.goal}\")\n",
    "\n",
    "            # --- LLM-driven planning/modification (Simulation) ---\n",
    "            # Iterate through components or target specific ones based on intent/goal\n",
    "            changes_made = False\n",
    "            components_to_check = list(self.state.component_intents.keys()) # Check all components for now\n",
    "\n",
    "            for component_name in components_to_check:\n",
    "                current_intent = self.state.component_intents[component_name]\n",
    "                current_code = self.state.component_code.get(component_name)\n",
    "\n",
    "                # Decide if this component is relevant to the goal\n",
    "                is_relevant = False\n",
    "                # Simple relevance check: does intent or component name contain keywords from the goal?\n",
    "                if self.state.goal and (any(keyword in component_name.lower() for keyword in self.state.goal.lower().split()) or\n",
    "                                        ('hints' in current_intent and any(hint in self.state.goal.lower() for hint in current_intent['hints'])) or\n",
    "                                        ('functions' in current_intent and any(func_name.lower() in self.state.goal.lower() for func_name in current_intent['functions']))):\n",
    "                    is_relevant = True\n",
    "\n",
    "                if is_relevant:\n",
    "                    logging.info(f\"Component '{component_name}' identified as potentially relevant to goal. Attempting code generation/modification.\")\n",
    "                    # Simulate LLM call\n",
    "                    new_code, modified = generate_or_modify_code(current_intent, current_code, self.state.goal)\n",
    "                    if modified:\n",
    "                        self.state.component_code[component_name] = new_code\n",
    "                        self.state.modified_components.add(component_name)\n",
    "                        changes_made = True\n",
    "                        logging.info(f\"Code for '{component_name}' modified.\")\n",
    "                    else:\n",
    "                         logging.info(f\"No modification made for '{component_name}' by simulated LLM.\")\n",
    "\n",
    "                else:\n",
    "                    logging.debug(f\"Component '{component_name}' not relevant to goal. Skipping code generation.\")\n",
    "\n",
    "\n",
    "            if changes_made:\n",
    "                logging.info(\"Code modifications were made. Next step: Assemble.\")\n",
    "                self.state.plan.append('assemble_components')\n",
    "            else:\n",
    "                logging.info(\"No significant code modifications made in this iteration. Next step: Assemble (if this is the first pass) or Monitor.\")\n",
    "                # If no code changes were made but we haven't run yet, we still need to assemble and run.\n",
    "                # If we've run and are in refinement, maybe skip assembly if no code changed?\n",
    "                # For simplicity, let's always assemble and run if we reached this step.\n",
    "                self.state.plan.append('assemble_components')\n",
    "\n",
    "\n",
    "        elif current_plan_step == 'assemble_components':\n",
    "            # Assemble the components into an executable system\n",
    "            self.state.current_task = 'Assembling the system'\n",
    "            # Pass only the code/intents of components that are part of the architecture or were modified\n",
    "            components_to_assemble_code = {name: self.state.component_code[name] for name in self.state.component_code if name in [n['name'] for n in self.state.architecture.get('nodes', [])] or name in self.state.modified_components}\n",
    "            components_to_assemble_intents = {name: self.state.component_intents[name] for name in self.state.component_intents if name in [n['name'] for n in self.state.architecture.get('nodes', [])] or name in self.state.modified_components}\n",
    "\n",
    "            assembled_dir, assembly_plan = assemble_components({'nodes': [{'name':n, 'intent': components_to_assemble_intents[n]} for n in components_to_assemble_intents]}, components_to_assemble_code, output_dir=f'assembled_{int(time.time())}')\n",
    "            self.state.current_task = f'System assembled in {assembled_dir}. Assembly plan: {assembly_plan}'\n",
    "            logging.info(self.state.current_task)\n",
    "\n",
    "            # Next step: Run the assembled system (orchestrate)\n",
    "            self.state.plan.append(('run_orchestrator', assembled_dir)) # Pass the assembled directory path\n",
    "\n",
    "\n",
    "        elif isinstance(current_plan_step, tuple) and current_plan_step[0] == 'run_orchestrator':\n",
    "             # Run the assembled system (orchestrator)\n",
    "             self.state.current_task = 'Running the orchestrated system'\n",
    "             assembled_dir_to_run = current_plan_step[1]\n",
    "             logging.info(f\"Running system from directory: {assembled_dir_to_run}\")\n",
    "             deployment_status, execution_result = package_and_deploy(assembled_dir_to_run, self.deployment_target) # package_and_deploy now runs the code for 'cli' target\n",
    "             self.state.last_execution_result = execution_result\n",
    "             self.state.current_task = f'Orchestration finished. Status: {deployment_status}'\n",
    "             logging.info(self.state.current_task)\n",
    "\n",
    "             # Next step: Monitor results and potentially refine\n",
    "             self.state.plan.append('monitor_and_refine')\n",
    "\n",
    "        elif current_plan_step == 'monitor_and_refine':\n",
    "            # Monitor results and decide if refinement is needed\n",
    "            self.state.current_task = 'Monitoring results and scoring'\n",
    "            logging.info(\"Monitoring and scoring execution results...\")\n",
    "\n",
    "            # Basic Monitoring: Check the execution result\n",
    "            if self.state.last_execution_result:\n",
    "                 score, feedback, needs_refinement = score_results(self.state.last_execution_result, self.state.goal)\n",
    "                 self.state.last_score = score\n",
    "                 logging.info(f\"Scoring results: Score={score}, Refine={needs_refinement}\")\n",
    "                 for fb in feedback:\n",
    "                      logging.info(f\"  - Feedback: {fb}\")\n",
    "\n",
    "\n",
    "                 if needs_refinement and self.state.refinement_count < self.refinement_limit:\n",
    "                     self.state.refinement_count += 1\n",
    "                     logging.warning(f\"Refinement needed (Attempt {self.state.refinement_count}/{self.refinement_limit}). Planning for refinement.\")\n",
    "                     # Plan for refinement: Go back to code generation/modification\n",
    "                     self.state.plan.append('generate_or_modify_code')\n",
    "                     # Clear modified components for the next refinement cycle\n",
    "                     self.state.modified_components = set()\n",
    "                     # Optionally, provide specific refinement instructions to the LLM simulation\n",
    "                     # self.state.refinement_instruction = f\"Execution failed or results were ambiguous. Feedback: {feedback}. Adjust code to address these issues.\"\n",
    "\n",
    "                 else:\n",
    "                     if needs_refinement and self.state.refinement_count >= self.refinement_limit:\n",
    "                         logging.error(f\"Refinement limit ({self.refinement_limit}) reached. Goal could not be fully achieved.\")\n",
    "                         self.state.current_task = f\"Goal '{self.state.goal}' failed after {self.refinement_limit} refinements. Last score: {self.state.last_score}\"\n",
    "                     else:\n",
    "                          logging.info(\"Goal appears to be achieved or no further refinement is planned.\")\n",
    "                          self.state.current_task = f\"Goal '{self.state.goal}' achieved (Score: {self.state.last_score})\"\n",
    "\n",
    "                     self.state.plan.append('finished') # Mark goal as finished\n",
    "\n",
    "\n",
    "            else:\n",
    "                 logging.warning(\"No execution result available to score.\")\n",
    "                 self.state.current_task = \"Monitoring step skipped due to no execution result.\"\n",
    "                 self.state.plan.append('finished') # If no run happened, we can't monitor, maybe just finish or rethink? Let's finish for now.\n",
    "\n",
    "\n",
    "        elif current_plan_step == 'finished':\n",
    "            self.state.current_task = \"Goal execution finished.\"\n",
    "            logging.info(self.state.current_task)\n",
    "            # The loop will terminate if the plan is empty\n",
    "\n",
    "\n",
    "        else:\n",
    "            logging.error(f\"Unknown plan step: {current_plan_step}\")\n",
    "            self.state.current_task = f\"Agent encountered an unknown plan step: {current_plan_step}. Stopping.\"\n",
    "            self.state.plan.clear() # Clear plan to stop loop\n",
    "\n",
    "\n",
    "        self.state.save(self.state_file)\n",
    "        self.last_action_time = time.time() # Update time of last action\n",
    "\n",
    "    def run(self, max_iterations=10, polling_interval=5, time_trigger_interval=60):\n",
    "        \"\"\"Runs the autonomous agent loop.\"\"\"\n",
    "        logging.info(f\"Starting agent loop for goal: '{self.state.goal}'\")\n",
    "        iteration = 0\n",
    "\n",
    "        # Ensure the project directory exists for scanning\n",
    "        if not os.path.exists(self.project_directory):\n",
    "            logging.error(f\"Project directory not found: {self.project_directory}. Cannot run.\")\n",
    "            return\n",
    "\n",
    "        # Initial scan and state capture if not loaded\n",
    "        if not self.state.file_state and os.path.exists(self.project_directory):\n",
    "             _, self.state.file_state = monitor_files(self.project_directory, {}) # Initial state capture\n",
    "\n",
    "        # Ensure initial scan is part of the plan if starting fresh\n",
    "        if not self.state.plan and not self.state.goal:\n",
    "             logging.error(\"Agent has no goal and no plan. Set a goal first.\")\n",
    "             return\n",
    "        elif not self.state.plan and self.state.goal:\n",
    "             # If goal is set but plan is empty (e.g., state file missing), start fresh\n",
    "             logging.warning(\"Agent has a goal but no plan. Starting planning from scan.\")\n",
    "             self.state.plan.append('scan_files')\n",
    "             self.state.save(self.state_file)\n",
    "\n",
    "\n",
    "        while self.state.plan and iteration < max_iterations and self.state.current_task != f\"Goal '{self.state.goal}' failed after {self.refinement_limit} refinements. Last score: {self.state.last_score}\":\n",
    "            iteration += 1\n",
    "            logging.info(f\"\\n--- Agent Loop Iteration {iteration} ---\")\n",
    "            logging.info(f\"Current Goal: {self.state.goal}\")\n",
    "            logging.info(f\"Current Task: {self.state.current_task}\")\n",
    "            logging.info(f\"Plan Queue Length: {len(self.state.plan)}\")\n",
    "            # logging.info(f\"Plan Queue: {list(self.state.plan)}\") # Be careful printing large plans\n",
    "\n",
    "            # --- File Monitoring (Passive Check) ---\n",
    "            # Check for external changes *before* planning the next automated step\n",
    "            changed_files, new_file_state = monitor_files(self.project_directory, self.state.file_state)\n",
    "            if changed_files:\n",
    "                 logging.warning(\"Detected external file changes. Re-scanning and adjusting plan.\")\n",
    "                 self.state.file_state = new_file_state\n",
    "                 # Insert a re-scan and re-evaluation into the plan\n",
    "                 self.state.plan.clear() # Clear current plan, start over with understanding new state\n",
    "                 self.state.plan.append('scan_files')\n",
    "                 self.state.modified_components = set() # Reset modifications if files changed externally\n",
    "                 self.state.last_execution_result = None # Invalidate previous result\n",
    "                 self.state.last_score = None\n",
    "                 self.state.refinement_count = 0 # Reset refinement count on external change\n",
    "                 self.state.save(self.state_file)\n",
    "                 # Skip further action in this iteration to process changes first\n",
    "                 continue # Go to the next iteration to process the updated plan\n",
    "\n",
    "\n",
    "            # --- Time Trigger Check ---\n",
    "            # Could trigger periodic checks, scans, or self-updates\n",
    "            # if check_time_trigger(self.last_action_time, time_trigger_interval):\n",
    "            #    logging.info(\"Time trigger initiating periodic check/update.\")\n",
    "               # Decide what to do on time trigger - e.g., re-scan, check external APIs, etc.\n",
    "               # For this prototype, we won't add complex time-triggered actions.\n",
    "               # The _plan_next_steps naturally follows a sequence.\n",
    "\n",
    "            # --- Execute next step in the plan ---\n",
    "            self._plan_next_steps()\n",
    "\n",
    "            if self.state.plan and self.state.plan[0] != 'finished':\n",
    "                 logging.info(f\"Sleeping for {polling_interval} seconds before next iteration...\")\n",
    "                 time.sleep(polling_interval) # Simple polling delay\n",
    "\n",
    "        logging.info(\"--- Agent Loop Finished ---\")\n",
    "        if iteration >= max_iterations:\n",
    "            logging.warning(f\"Agent loop terminated after maximum {max_iterations} iterations.\")\n",
    "        elif self.state.current_task == f\"Goal '{self.state.goal}' failed after {self.refinement_limit} refinements. Last score: {self.state.last_score}\":\n",
    "             logging.error(f\"Agent loop terminated because goal failed after {self.refinement_limit} refinements.\")\n",
    "        else:\n",
    "            logging.info(\"Agent loop terminated as plan is complete.\")\n",
    "        logging.info(f\"Final Task: {self.state.current_task}\")\n",
    "        logging.info(f\"Final Score: {self.state.last_score}\")\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# Clean up previous runs and state file\n",
    "!rm -rf project_components assembled_* agent_state.json\n",
    "\n",
    "# Create dummy project directory and files\n",
    "!mkdir -p project_components\n",
    "!echo \"def process_data(data):\\\\n    # This function could incur cost based on data volume\\\\n    print(f'Processing data of size: {len(data)}')\\\\n    processed_data = [x * 2 for x in data]\\\\n    print(f'Finished processing. Result size: {len(processed_data)}')\\\\n    return processed_data\" > project_components/processor.py\n",
    "!echo \"def load_config(path):\\\\n    with open(path, 'r') as f:\\\\n        config = json.load(f)\\\\n    print(f'Loaded config: {config}')\\\\n    return config\" > project_components/config_loader.py\n",
    "!echo '{\"multiplier\": 2, \"processing_cost_per_unit\": 0.01}' > project_components/config.json\n",
    "!echo \"import processor\\\\nimport config_loader\\\\nimport json\\\\n\\\\ndef calculate_total_cost(processed_data, config):\\\\n    cost_per_unit = config.get('processing_cost_per_unit', 0)\\\\n    total_cost = len(processed_data) * cost_per_unit\\\\n    print(f'Calculated total cost: {total_cost:.2f}')\\\\n    return total_cost\\\\n\\\\ndef main():\\\\n    config = config_loader.load_config('project_components/config.json')\\\\n    initial_data = list(range(100)) # Simulate some data\\\\n    print(f'Initial data size: {len(initial_data)}')\\\\n    processed = processor.process_data(initial_data)\\\\n    total_cost = calculate_total_cost(processed, config)\\\\n    print(f'Main execution finished. Total Cost: {total_cost:.2f}')\\\\n\\\\nif __name__ == '__main__':\\\\n    main()\" > project_components/main.py\n",
    "!echo \"This is a readme file.\" > project_components/README.md\n",
    "\n",
    "# --- Create the Agent ---\n",
    "# Specify the project directory to monitor\n",
    "agent = FullSelfDrivingAgent(project_directory=\"project_components\")\n",
    "\n",
    "# --- Set a High-Level Goal ---\n",
    "# The agent will try to achieve this goal by modifying/orchestrating code\n",
    "# goal = \"launch pricing module\" # This goal will trigger generation of a pricing function\n",
    "goal = \"optimize cost structure\" # This goal will look for cost hints and simulate optimization\n",
    "# goal = \"calculate budget allocation\" # Example of a goal the agent might not fully achieve with current code\n",
    "\n",
    "agent.set_goal(goal)\n",
    "\n",
    "# --- Run the Agent Loop ---\n",
    "# The agent will now execute its internal plan to try and achieve the goal\n",
    "# Adjust max_iterations and polling_interval as needed\n",
    "agent.run(max_iterations=10, polling_interval=2)\n",
    "\n",
    "print(\"\\n--- Agent Process Complete ---\")\n",
    "print(f\"Final Agent Task Status: {agent.state.current_task}\")\n",
    "print(f\"Final Agent Score: {agent.state.last_score}\")\n",
    "\n",
    "# You can inspect the 'assembled_*' directory to see the generated/modified code\n",
    "# You can also inspect 'agent_state.json' to see the agent's final state\n",
    "\n",
    "# Clean up the assembled directories after inspection if desired\n",
    "# !rm -rf assembled_*\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
